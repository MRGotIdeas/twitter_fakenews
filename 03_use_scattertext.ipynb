{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6502aef",
   "metadata": {},
   "source": [
    "## Use scattertext\n",
    "\n",
    "Voir issue : https://github.com/MRGotIdeas/twitter_fakenews/issues/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f723854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import fr_core_news_md\n",
    "import scattertext as sc\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac18a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ManonRICHARD\\Documents\\PFE\\twitter-fakenews\\data\n"
     ]
    }
   ],
   "source": [
    "%cd ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f882397",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_tweets.txt\", \"rb\") as file :  \n",
    "    data_tweets = pickle.load(file)\n",
    "\n",
    "data_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets[[\"liability\", \"liability_label\"]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb89bcbe",
   "metadata": {},
   "source": [
    "#### Création tag fake / pas fake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f66221",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets[\"fakenews\"] = \"fiable\"\n",
    "data_tweets.loc[data_tweets[\"liability\"].isin([2, 3]), \"fakenews\"] = \"pas fiable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets = data_tweets.loc[data_tweets[\"liability_label\"] != \"site parodique\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ae971",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b8779",
   "metadata": {},
   "source": [
    "## Nettoyage du texte\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f2be85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on charge le modèle français de spacy\n",
    "nlp = fr_core_news_md.load()\n",
    "\n",
    "# On rajoute dans des stopwords à la liste de stopwords proposée par spacy\n",
    "#nlp.Defaults.stop_words |= {\"mlp\",\"a\",\"faut\",\"faire\",\"monsieur\",\"rendez-vous\",\"direct\",\n",
    "#                            \"interview\",r\"invité\\w+\",\"dit\",\"livetweet\",\"suivez\",\"celui\",\n",
    "#                            \"ce\",\"cette\",\"emot_right_arrow\"}\n",
    "\n",
    "# nombre de stopwords \n",
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc72876",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_hashtags = re.compile(r\"[#@]\\w+\")    # suppression des hashtags et @\n",
    "regexp_link = re.compile(r\"http\\S+\") # suppression des liens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3167013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(doc):\n",
    "    return [token for token in doc if not token.is_punct]\n",
    "\n",
    "\n",
    "def remove_stop_words(doc):\n",
    "    return [token for token in doc if not token.is_stop]\n",
    "\n",
    "\n",
    "def lemmatize(doc):\n",
    "    return ' '.join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(text, lemmatizing=False, delete_pos=False) : \n",
    "\n",
    "    '''Fonction permettant de nettoyer le texte. Elle renvoie un string (pas de tokenisation encore)'''\n",
    "  \n",
    "    #emojis_converted = convert_emojis(text)\n",
    "    #french_flag_added = re.sub(regexp_frenchflag, \"french_flag\", emojis_converted)\n",
    "    text_to_lower = text.lower().encode('utf-8').decode('utf-8')\n",
    "    text_no_link = re.sub(regexp_link, \"desident_link\", text_to_lower)\n",
    "    text_no_hastags = re.sub(regexp_hashtags, \"desident_hashtag\", text_no_link)\n",
    "          \n",
    "    # utilisation de spacy\n",
    "    doc = nlp(text_no_hastags)\n",
    "    removed_punct = remove_punct(doc)\n",
    "    preprocessed_tweet = remove_stop_words(removed_punct)\n",
    "    if lemmatizing :\n",
    "        preprocessed_tweet = lemmatize(preprocessed_tweet)\n",
    "            \n",
    "    return(preprocessed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut alors nettoyer nos tweets, et créer une nouvelle colonne, text_preprocess\n",
    "# cela peut prendre un peu de temps... \n",
    "data_tweets[\"tweet_preprocess\"] = data_tweets[\"tweet\"].apply(lambda tweet : preprocess_tweet(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb39506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_tweets[\"tweet_preprocess\"] = data_tweets[\"tweet_preprocess\"].apply(lambda list_txt : \" \".join(str(v) for v in list_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets[\"tweet_preprocess\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde le résultat du nettoyage du texte\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "data_tweets[[\"tweet\", \"tweet_preprocess\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_tweets_preprocess.txt\", \"wb\") as fp :   #Pickling\n",
    "    pickle.dump(data_tweets, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e38c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_tweets_preprocess.txt\", \"rb\") as file :  \n",
    "    data_tweets = pickle.load(file)\n",
    "\n",
    "data_tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ce764",
   "metadata": {},
   "source": [
    "### Filtre et échantillonnage"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40f2d0f0",
   "metadata": {},
   "source": [
    "pd.set_option(\"max_colwidth\",None)\n",
    "tt = data_tweets[data_tweets[\"description\"].str.contains('anglais|américain', regex= True, na=False)]\n",
    "tt[[\"tweet_preprocess\",\"description\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "113ff8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759098, 13)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On enlève les tweets anglais / italiens\n",
    "# -> ont une description qui indique que c'est un média anglais ou américain\n",
    "data_tweets = data_tweets[~data_tweets[\"description\"].str.contains('anglais|américain|italien', regex= True, na=False)]\n",
    "data_tweets = data_tweets[~data_tweets[\"tweet_preprocess\"].str.contains(\"don' t\", regex= True, na=False)]\n",
    "data_tweets.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8030d5f",
   "metadata": {},
   "source": [
    "tt = data_tweets[data_tweets[\"tweet\"].str.contains(r'local law', regex= True, na=False)]\n",
    "tt[[\"tweet_preprocess\",\"description\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a51ebd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759098, 13)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On enlève les lignes de la base de données où twitter nous informe que le compte a été supprimé \n",
    "# 7 comptes dans la base de données ont été supprimés à cause de lois françaises\n",
    "data_tweets = data_tweets[~data_tweets[\"tweet\"].str.contains(r'local law', regex= True, na=False)]\n",
    "data_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96f7796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "RANDOM_SEED = 34564324\n",
    "\n",
    "sample_tweets_fk = data_tweets.loc[data_tweets[\"fakenews\"]==\"fiable\"].sample(n=N, random_state=RANDOM_SEED)\n",
    "sample_tweets_nfk = data_tweets.loc[data_tweets[\"fakenews\"]==\"pas fiable\"].sample(n=N, random_state=RANDOM_SEED)\n",
    "\n",
    "sample_tweets = pd.concat([sample_tweets_fk, sample_tweets_nfk], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48febb7f",
   "metadata": {},
   "source": [
    "## Scattertext\n",
    "\n",
    "\n",
    "- Mettre les mots en minuscule\n",
    "- Transformation des liens internet en \"desident_link\"\n",
    "- transformation des ! en \"desident_exclamation\"\n",
    "- transformation des ? en \"desident_question\"\n",
    "- Suppression des stop words (vous pouvez utiliser spacy)\n",
    "- Suppression de la ponctuaction\n",
    "- lemmatisation et sans lemmatisation (dans un premier temps, lancer scattertext sans, puis avec ensuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd598f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on crée un objet corpus pour scattertext\n",
    "corpus = sc.CorpusFromPandas(data_frame = sample_tweets,\n",
    "                             category_col = \"fakenews\",\n",
    "                             text_col = \"tweet_preprocess\",\n",
    "                             nlp = nlp).build()#.compact(sc.AssociationCompactor(4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "890dcc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3210272"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On crée le html du scattertext\n",
    "html = sc.produce_scattertext_explorer(  corpus\n",
    "                                       , category                  = 'pas fiable'\n",
    "                                       , category_name             = 'pas fiable'\n",
    "                                       , not_category_name         = 'fiable'\n",
    "                                       , minimum_term_frequency    = 10\n",
    "                                       , pmi_threshold_coefficient = 1\n",
    "                                       , term_ranker               = sc.AbsoluteFrequencyRanker\n",
    "                                       , transform                 = sc.Scalers.dense_rank\n",
    "                                       , term_scorer               = sc.RankDifference() \n",
    "#on peut égalemet tester le term_scorer ScaledFscore : st.ScaledFScorePresets(beta=1, one_to_neg_one=True)\n",
    "                                       , width_in_pixels           = 1000\n",
    "                                       )\n",
    "\n",
    "# On enregistre le html\n",
    "open(\"tweets_visualisation.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71777c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2568483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9be13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0685f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
