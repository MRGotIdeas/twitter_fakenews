{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fafa80",
   "metadata": {},
   "source": [
    "# Récupération des données twitter\n",
    "\n",
    "A partir des comptes twitter issus de Decodex, on récupère les données de twitter correspondants à ces comptes : \n",
    "    - les abonnés ; \n",
    "    - les tweets ; \n",
    "    - les retweets et likes ; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6d691",
   "metadata": {},
   "source": [
    "#### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818d29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tweepy as tw\n",
    "import re\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5833434",
   "metadata": {},
   "source": [
    "##### Récupération clés twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c303e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ManonRICHARD\\Documents\\PFE\\twitter-fakenews\\data\n"
     ]
    }
   ],
   "source": [
    "%cd ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0bb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = eval(open(\"api_twitter_keys.txt\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7614919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['consumer_key', 'consumer_secret', 'access_token', 'access_token_secret'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_keys.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d23acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token'], twitter_keys['access_token_secret'])\n",
    "api = tw.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a96a9",
   "metadata": {},
   "source": [
    "## Import données Decodex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5460f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodex_data = pd.read_csv(\"twitter_accounts_decodex.csv\", sep=\";\")\n",
    "decodex_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd843ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodex_data['path_website'] = decodex_data['path_website'].apply(lambda txt : re.sub('twitter.(com|fr)/', '', txt))\n",
    "decodex_data['path_website'] = decodex_data['path_website'].apply(lambda txt : re.sub(r'\\?lang=fr', '', txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodex_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3108cc",
   "metadata": {},
   "source": [
    "## Récupération des tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb69781",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extraction d'autant de tweets anciens possibles (et pas seulement limite 200) d'un userID\n",
    "def extract_all_tweets_from_user(userID) :\n",
    "\n",
    "    tweets = api.user_timeline(screen_name=userID, \n",
    "                               # 200 is the maximum allowed count\n",
    "                               count=200,\n",
    "                               include_rts = False,\n",
    "                               # Necessary to keep full_text \n",
    "                               # otherwise only the first 140 words are extracted\n",
    "                               tweet_mode = 'extended'\n",
    "                               )\n",
    "  \n",
    "    all_tweets = []\n",
    "    all_tweets.extend(tweets)\n",
    "    oldest_id = tweets[-1].id\n",
    "    \n",
    "    while True:\n",
    "        tweets = api.user_timeline(screen_name=userID, \n",
    "                                   # 200 is the maximum allowed count\n",
    "                                   count=200,\n",
    "                                   include_rts = False,\n",
    "                                   max_id = oldest_id - 1,\n",
    "                                   # Necessary to keep full_text \n",
    "                                   # otherwise only the first 140 words are extracted\n",
    "                                   tweet_mode = 'extended'\n",
    "                                   )\n",
    "        if len(tweets) == 0:\n",
    "            break\n",
    "            \n",
    "        oldest_id = tweets[-1].id\n",
    "        all_tweets.extend(tweets)\n",
    "        #print('N of tweets downloaded till now {}'.format(len(all_tweets)))\n",
    "        \n",
    "    return(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ee279",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On récupère les tweets de tous les sites\n",
    "%time\n",
    "tweets_all_accounts = []\n",
    "accounts_not_found = []\n",
    "count_action = 0\n",
    "for tweet_account in decodex_data['path_website'] : \n",
    "    \n",
    "    # get tweets from tweet account : \n",
    "    try:\n",
    "        all_tweets_account = extract_all_tweets_from_user(tweet_account)\n",
    "        \n",
    "    except:\n",
    "        print(f\"No tweet collected from {tweet_account}\")\n",
    "        accounts_not_found.append(tweet_account)\n",
    "        pass\n",
    "    \n",
    "    if len(all_tweets_account) > 0 : \n",
    "        tweets_all_accounts.append(all_tweets_account)\n",
    "        \n",
    "    # get all followers of tweet account : \n",
    "    \n",
    "        \n",
    "    count_action += 1\n",
    "    \n",
    "    if (count_action % 10) == 0: \n",
    "        print(count_action)\n",
    "        print(tweet_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef205cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accounts_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a54e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_all_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd96dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_tweet(all_tweets) :\n",
    "    df_all = pd.DataFrame(columns=[\"id\", \"created_at\", \"favorite_count\", \"retweet_count\", \"text\"])\n",
    "    for elem in all_tweets  :\n",
    "        outtweets = [[tweet.id_str,\n",
    "                      tweet.user.screen_name,\n",
    "                      tweet.created_at, \n",
    "                      tweet.favorite_count, \n",
    "                      tweet.retweet_count, \n",
    "                      tweet.full_text.encode(\"utf-8\").decode(\"utf-8\")] \n",
    "                     for idx, tweet in enumerate(elem)]\n",
    "        df = pd.DataFrame(outtweets,columns=[\"id\", \"user\", \"created_at\", \"favorite_count\", \"retweet_count\", \"text\"])\n",
    "        df_all = pd.concat([df_all, df])\n",
    "\n",
    "    return(df_all)\n",
    "\n",
    "# https://www.geeksforgeeks.org/python-status-object-in-tweepy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dc44cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweets_format = create_df_tweet(tweets_all_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_format.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6c57da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020089"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tweets_format) # 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb953256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1RiposteLaique</th>\n",
       "      <td>3200</td>\n",
       "      <td>3200</td>\n",
       "      <td>3200</td>\n",
       "      <td>3200</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20Minutes</th>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9GAG</th>\n",
       "      <td>3230</td>\n",
       "      <td>3230</td>\n",
       "      <td>3230</td>\n",
       "      <td>3230</td>\n",
       "      <td>3230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>3077</td>\n",
       "      <td>3077</td>\n",
       "      <td>3077</td>\n",
       "      <td>3077</td>\n",
       "      <td>3077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE911Truth</th>\n",
       "      <td>3174</td>\n",
       "      <td>3174</td>\n",
       "      <td>3174</td>\n",
       "      <td>3174</td>\n",
       "      <td>3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washingtonpost</th>\n",
       "      <td>3125</td>\n",
       "      <td>3125</td>\n",
       "      <td>3125</td>\n",
       "      <td>3125</td>\n",
       "      <td>3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikiHow</th>\n",
       "      <td>3177</td>\n",
       "      <td>3177</td>\n",
       "      <td>3177</td>\n",
       "      <td>3177</td>\n",
       "      <td>3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtvdesinfo</th>\n",
       "      <td>2986</td>\n",
       "      <td>2986</td>\n",
       "      <td>2986</td>\n",
       "      <td>2986</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wucnews</th>\n",
       "      <td>6392</td>\n",
       "      <td>6392</td>\n",
       "      <td>6392</td>\n",
       "      <td>6392</td>\n",
       "      <td>6392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yetiblog</th>\n",
       "      <td>2058</td>\n",
       "      <td>2058</td>\n",
       "      <td>2058</td>\n",
       "      <td>2058</td>\n",
       "      <td>2058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  created_at  favorite_count  retweet_count  text\n",
       "user                                                                 \n",
       "1RiposteLaique  3200        3200            3200           3200  3200\n",
       "20Minutes       2875        2875            2875           2875  2875\n",
       "9GAG            3230        3230            3230           3230  3230\n",
       "ABC             3077        3077            3077           3077  3077\n",
       "AE911Truth      3174        3174            3174           3174  3174\n",
       "...              ...         ...             ...            ...   ...\n",
       "washingtonpost  3125        3125            3125           3125  3125\n",
       "wikiHow         3177        3177            3177           3177  3177\n",
       "worldtvdesinfo  2986        2986            2986           2986  2986\n",
       "wucnews         6392        6392            6392           6392  6392\n",
       "yetiblog        2058        2058            2058           2058  2058\n",
       "\n",
       "[377 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_format.groupby('user').count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f91ef68c",
   "metadata": {},
   "source": [
    "for elem in tweets_all_accounts  :\n",
    "    for idx, tweet in enumerate(elem) : \n",
    "        print(tweet.user.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805a0d6",
   "metadata": {},
   "source": [
    "### Export des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45bf54fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets_all_accounts.txt\", \"wb\") as fp :   #Pickling\n",
    "    pickle.dump(df_tweets_format, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abb337",
   "metadata": {},
   "source": [
    "### Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8018e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets_all_accounts.txt\", \"rb\") as file :   \n",
    "    tweets_all_accounts = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f40da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_all_accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3df9700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020089"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_all_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57502178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
